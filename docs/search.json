[
  {
    "objectID": "AULA 1.html",
    "href": "AULA 1.html",
    "title": "AULA 1",
    "section": "",
    "text": "data <- c(0:10)\nplot(data)\n\n\n\npng(\"plot.png\")\ndev.off()\n\npng \n  2 \n\npng(\"plot.png\", width = 100, height = 100)\n\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85"
  },
  {
    "objectID": "AULA 10.html",
    "href": "AULA 10.html",
    "title": "AULA 10",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(viridis)\nlibrary(viridisLite)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"micelial\")\nhead(micelial)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.24\n6 Fasi        6  1.29\n\nmicelial |> \n  ggplot(aes(especie, tcm, fill = especie)) + \n  geom_boxplot() + \n  scale_fill_manual(values = viridis_pal(option = \"viridis\")(5), labels = expression(italic(\"F. asiaticum\"), italic(\"F. austroamericanum\"), italic(\"F. castaderiae\"), italic(\"F. graminearum\"), italic(\"F. meridionale\"))) +\n  labs (y = \"Mycelium Growth Rate\", x = \" \", fill = \"Species\") +\n    theme_classic()\n\n\n\nggsave(\"MGR.jpeg\", dpi = 300, width = 9, height = 6)\n\n\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915               \n\n\n\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\n\n##Normality test\n\nhist(aov1$residuals)\n\n\n\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n\n\n\n\n\nshapiro.test(aov1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aov1$residuals\nW = 0.95101, p-value = 0.07022\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov1))\n\n\n\n\n\ninsects <- as_tibble(InsectSprays) |> \n  select(spray, count)\n\ninsects |> \n  ggplot(aes(x = spray, y = count)) +\n  geom_boxplot()\n\n\n\n\n\naov2 <- aov(sqrt(count) ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncheck_heteroscedasticity(aov2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\ncheck_normality(aov2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\n\n\nlibrary(emmeans)\naov2_means <- emmeans(aov2, ~ spray,\n                      type = \"response\")\naov2_means\n\n spray response    SE df lower.CL upper.CL\n A        14.14 1.364 66   11.550    17.00\n B        15.03 1.406 66   12.352    17.97\n C         1.55 0.452 66    0.779     2.58\n D         4.68 0.785 66    3.248     6.38\n E         3.27 0.656 66    2.095     4.72\n F        16.15 1.458 66   13.370    19.19\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\npwpm(aov2_means)\n\n        A       B       C       D       E       F\nA [14.14]  0.9975  <.0001  <.0001  <.0001  0.9145\nB  -0.116 [15.03]  <.0001  <.0001  <.0001  0.9936\nC   2.516   2.632 [ 1.55]  0.0081  0.2513  <.0001\nD   1.596   1.712  -0.919 [ 4.68]  0.7366  <.0001\nE   1.951   2.067  -0.565   0.355 [ 3.27]  <.0001\nF  -0.258  -0.142  -2.774  -1.854  -2.209 [16.15]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(aov2_means)\n\n spray response    SE df lower.CL upper.CL .group\n C         1.55 0.452 66    0.779     2.58  1    \n E         3.27 0.656 66    2.095     4.72  12   \n D         4.68 0.785 66    3.248     6.38   2   \n A        14.14 1.364 66   11.550    17.00    3  \n B        15.03 1.406 66   12.352    17.97    3  \n F        16.15 1.458 66   13.370    19.19    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\nkruskal(insects$count, insects$spray,\n        console = TRUE)\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n\n\n\nglm1 <- glm(count ~ spray,\n            data = insects,\n            family = poisson(link = \"identity\"))\nplot(simulateResiduals(glm1))\n\n\n\nsummary(glm1)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3\n\nglm1_means <- emmeans(glm1, ~ spray)\ncld(glm1_means)\n\n spray emmean    SE  df asymp.LCL asymp.UCL .group\n C       2.08 0.417 Inf      1.27      2.90  1    \n E       3.50 0.540 Inf      2.44      4.56  12   \n D       4.92 0.640 Inf      3.66      6.17   2   \n A      14.50 1.099 Inf     12.35     16.65    3  \n B      15.33 1.130 Inf     13.12     17.55    3  \n F      16.67 1.179 Inf     14.36     18.98    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "AULA 11.html",
    "href": "AULA 11.html",
    "title": "AULA 11",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\ndat <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\n\ndat2 <- dat |> \n  mutate(inc = dis_sp/n_sp*100)\n\ndat2 |> \n  ggplot(aes(x = treat,\n             y = inc)) + \n  geom_jitter(width = 0.1) +\n  facet_wrap(~dose)\n\n\n\n\n\nm1 <- aov(inc ~ treat*dose,\n          data = dat2)\n\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ntreat        1  919.5   919.5   24.31 0.000151 ***\ndose         1  920.9   920.9   24.34 0.000150 ***\ntreat:dose   1  747.7   747.7   19.76 0.000407 ***\nResiduals   16  605.3    37.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.018).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\n\n\nm2 <- aov(log(inc+0.5) ~ treat*dose,\n          data = dat2)\n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 12.928  12.928  13.980 0.00179 **\ndose         1  5.663   5.663   6.124 0.02491 * \ntreat:dose   1  5.668   5.668   6.129 0.02486 * \nResiduals   16 14.796   0.925                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\ncheck_normality(m2)\n\nWarning: Non-normality of residuals detected (p = 0.050).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.180).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\n\nlibrary(emmeans)\nmeans_m1 <- emmeans(m1, ~treat|dose,\n                    type = \"response\")\nmeans_m1\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL\n Ionic liquid  29.21 2.75 16   23.379    35.04\n Tebuconazole   2.10 2.75 16   -3.731     7.93\n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL\n Ionic liquid   4.48 2.51 16   -0.848     9.80\n Tebuconazole   2.08 3.08 16   -4.444     8.59\n\nConfidence level used: 0.95 \n\n\n\nmeans_m2 <- emmeans(m2, ~treat|dose,\n                    type = \"response\")\nmeans_m2\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid    27.05 11.847 16   10.570    68.05\n Tebuconazole     1.21  0.737 16    0.188     3.76\n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid     3.10  1.412 16    1.065     7.77\n Tebuconazole     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\n\n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_m1)\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   2.10 2.75 16   -3.731     7.93  1    \n Ionic liquid  29.21 2.75 16   23.379    35.04   2   \n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   2.08 3.08 16   -4.444     8.59  1    \n Ionic liquid   4.48 2.51 16   -0.848     9.80  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(means_m2)\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.21  0.737 16    0.188     3.76  1    \n Ionic liquid    27.05 11.847 16   10.570    68.05   2   \n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.42  0.925 16    0.194     4.83  1    \n Ionic liquid     3.10  1.412 16    1.065     7.77  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n#Coefficient of Variance\n\nlibrary(agricolae)\ncv.model(m1)\n\n[1] 64.16788\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"armazena\")\n\nmilho |> \n  filter(tempo == 8) |> \n  ggplot(aes(factor(tipo), peso_mil, color = factor(umidade))) +\n  geom_jitter() + facet_wrap(~umidade)\n\n\n\n\n\nmilho2 <- milho |> \n  filter(tempo == 8)\n\nm2 <- aov(peso_mil ~factor(tipo)*factor(umidade), data = milho2)\n\nsummary(m2)\n\n                             Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  < 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm4 <- aov(yield ~hybrid*method,\n          data = milho3)\n\nsummary(m4)\n\n              Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\n\n\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm5 <- aov(yield~hybrid,\n          data = milho3)\n\nsummary(m4)\n\n              Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\ncheck_heteroscedasticity(m4)\n\nOK: Error variance appears to be homoscedastic (p = 0.928).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m4))\n\n\n\n\n\nmedias_m4 <- emmeans(m4, ~hybrid)\nmedias_m4\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 564 36     9453    11742\n 30F53 YH   9309 564 36     8165    10454\n 30K64     11018 564 36     9874    12162\n 30S31H     8652 564 36     7507     9796\n 30S31YH    8056 564 36     6912     9201\n BG7049H   12402 564 36    11257    13546\n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \n\ncld(medias_m4)\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 564 36     6912     9201  1    \n 30S31H     8652 564 36     7507     9796  12   \n 30F53 YH   9309 564 36     8165    10454  12   \n 30F53 HX  10598 564 36     9453    11742   23  \n 30K64     11018 564 36     9874    12162   23  \n BG7049H   12402 564 36    11257    13546    3  \n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\npwpm(medias_m4)\n\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5947  0.9947  0.1703  0.0328  0.2365\n30F53 YH     1288  [ 9309]  0.2900  0.9611  0.6228  0.0054\n30K64        -420    -1709 [11018]  0.0553  0.0084  0.5194\n30S31H       1946      658    2366 [ 8652]  0.9746  0.0005\n30S31YH      2541     1253    2962     595 [ 8056]  <.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(medias_m4)"
  },
  {
    "objectID": "AULA 12.html",
    "href": "AULA 12.html",
    "title": "AULA 12",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\nfungicidas <- read_excel (\"dados-diversos.xlsx\", \"fungicida_campo\")\n\n##ANova Block Model\n\naov_fung <- aov(sev ~trat + rep, data = fungicidas)\nsummary(aov_fung)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \ntrat         7   7135  1019.3 287.661 <2e-16 ***\nrep          1     19    18.6   5.239 0.0316 *  \nResiduals   23     81     3.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\nlibrary(DHARMa)\ncheck_normality(aov_fung)\n\nOK: residuals appear as normally distributed (p = 0.230).\n\ncheck_heteroscedasticity(aov_fung)\n\nOK: Error variance appears to be homoscedastic (p = 0.484).\n\nplot(simulateResiduals(aov_fung))\n\n\n\n\n\nlibrary(emmeans)\nmeans_fung <- emmeans(aov_fung, ~trat)\nsummary(means_fung)\n\n trat       emmean    SE df lower.CL upper.CL\n A            30.4 0.941 23     28.4     32.3\n B            29.5 0.941 23     27.6     31.4\n C            30.4 0.941 23     28.4     32.3\n D            31.5 0.941 23     29.6     33.4\n E            30.1 0.941 23     28.2     32.1\n F            35.5 0.941 23     33.6     37.4\n G            29.2 0.941 23     27.3     31.2\n testemunha   75.8 0.941 23     73.8     77.7\n\nConfidence level used: 0.95 \n\n\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_fung)\n\n trat       emmean    SE df lower.CL upper.CL .group\n G            29.2 0.941 23     27.3     31.2  1    \n B            29.5 0.941 23     27.6     31.4  1    \n E            30.1 0.941 23     28.2     32.1  1    \n C            30.4 0.941 23     28.4     32.3  1    \n A            30.4 0.941 23     28.4     32.3  1    \n D            31.5 0.941 23     29.6     33.4  12   \n F            35.5 0.941 23     33.6     37.4   2   \n testemunha   75.8 0.941 23     73.8     77.7    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(means_fung) + \n  coord_flip() +\n  theme_bw()\n\n\n\n\n##Subdivided Plot (Split-plot)\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\n\naov_milho_bloco <- aov(index ~factor(block) + hybrid*method + Error(factor(block)/hybrid/method), data = milho)\n\nsummary(aov_milho_bloco)\n\n\nError: factor(block)\n              Df Sum Sq Mean Sq\nfactor(block)  3  592.2   197.4\n\nError: factor(block):hybrid\n          Df Sum Sq Mean Sq F value Pr(>F)  \nhybrid     5  974.2  194.84    3.14 0.0389 *\nResiduals 15  930.9   62.06                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: factor(block):hybrid:method\n              Df Sum Sq Mean Sq F value Pr(>F)  \nmethod         1  79.61   79.61   4.726 0.0433 *\nhybrid:method  5 265.28   53.06   3.150 0.0324 *\nResiduals     18 303.18   16.84                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(lme4)\n\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(index ~block + hybrid*method + (1|block/hybrid), data = milho)\n\nanova(mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nblock            3   5.376   1.792  0.1064\nhybrid           5 264.420  52.884  3.1397\nmethod           1  79.606  79.606  4.7262\nhybrid:method    5 265.281  53.056  3.1500\n\nlibrary(performance)\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.621).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\nmilho$block <- as.factor(milho$block)\nmix3 <- lmer(sqrt(index) ~ block + hybrid*method + (1|block/hybrid), data = milho)\n\n\nlibrary(car)\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nblock          0.0764  3   0.994506   \nhybrid        15.4171  5   0.008721 **\nmethod         3.9239  1   0.047605 * \nhybrid:method 13.3025  5   0.020703 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.422).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\n\n\nmeans_mix2 <- emmeans(mix2, ~hybrid| method)\nsummary(means_mix2)\n\nmethod = pin:\n hybrid   emmean   SE  df lower.CL upper.CL\n 30F53 HX   25.3 6.87 524    11.78     38.8\n 30F53 YH   24.6 6.87 524    11.10     38.1\n 30K64      20.6 6.87 524     7.06     34.1\n 30S31H     38.1 6.87 524    24.62     51.6\n 30S31YH    32.5 6.87 524    19.00     46.0\n BG7049H    19.4 6.87 524     5.95     32.9\n\nmethod = silk:\n hybrid   emmean   SE  df lower.CL upper.CL\n 30F53 HX   25.0 6.87 524    11.50     38.5\n 30F53 YH   26.2 6.87 524    12.74     39.7\n 30K64      21.5 6.87 524     7.96     35.0\n 30S31H     26.5 6.87 524    13.01     40.0\n 30S31YH    26.7 6.87 524    13.17     40.2\n BG7049H    19.2 6.87 524     5.67     32.7\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n\n\ncld(means_mix2)\n\nmethod = pin:\n hybrid   emmean   SE  df lower.CL upper.CL .group\n BG7049H    19.4 6.87 524     5.95     32.9  1    \n 30K64      20.6 6.87 524     7.06     34.1  1    \n 30F53 YH   24.6 6.87 524    11.10     38.1  12   \n 30F53 HX   25.3 6.87 524    11.78     38.8  12   \n 30S31YH    32.5 6.87 524    19.00     46.0  12   \n 30S31H     38.1 6.87 524    24.62     51.6   2   \n\nmethod = silk:\n hybrid   emmean   SE  df lower.CL upper.CL .group\n BG7049H    19.2 6.87 524     5.67     32.7  1    \n 30K64      21.5 6.87 524     7.96     35.0  1    \n 30F53 HX   25.0 6.87 524    11.50     38.5  1    \n 30F53 YH   26.2 6.87 524    12.74     39.7  1    \n 30S31H     26.5 6.87 524    13.01     40.0  1    \n 30S31YH    26.7 6.87 524    13.17     40.2  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmeans_mix3 <- emmeans(mix3, ~method| hybrid)\ncld(means_mix3)\n\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     4.94 1.17 5356     2.64     7.25  1    \n pin      5.00 1.17 5356     2.69     7.30  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      4.95 1.17 5356     2.65     7.25  1    \n silk     5.10 1.17 5356     2.80     7.41  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      4.50 1.17 5356     2.20     6.81  1    \n silk     4.61 1.17 5356     2.31     6.91  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     5.13 1.17 5356     2.83     7.43  1    \n pin      6.10 1.17 5356     3.79     8.40   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     5.14 1.17 5356     2.84     7.44  1    \n pin      5.63 1.17 5356     3.33     7.93  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     4.37 1.17 5356     2.07     6.67  1    \n pin      4.40 1.17 5356     2.10     6.71  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "AULA 13.html",
    "href": "AULA 13.html",
    "title": "AULA 13",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\nestande |>\n  ggplot(aes(trat, nplants,))+\n  geom_point()+\n   facet_wrap(~exp)+\n    ylim(0, max(estande$nplants))\n\n\n\ngeom_smooth(se = F, method = \"lm\")\n\ngeom_smooth: na.rm = FALSE, orientation = NA, se = FALSE\nstat_smooth: na.rm = FALSE, orientation = NA, se = FALSE, method = lm\nposition_identity \n\nestande\n\n# A tibble: 72 × 4\n     exp  trat bloco nplants\n   <dbl> <dbl> <dbl>   <dbl>\n 1     1     0     1      66\n 2     1     0     2      72\n 3     1     0     3      50\n 4     1     0     4      27\n 5     1     3     1      68\n 6     1     3     2      79\n 7     1     3     3      31\n 8     1     3     4      32\n 9     1     6     1      58\n10     1     6     2      56\n# ℹ 62 more rows\n\n\n\nexp1 <- estande |>\n  filter(exp == 1) \nm1 <- lm(nplants ~trat, data = exp1)\nsummary(m1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\n\nexp2 <- estande |>\n  filter(exp == 2) \nm2 <- lm(nplants ~trat, data = exp2)\nsummary(m2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\nexp3 <- estande |>\n  filter(exp == 3) \nm3 <- lm(nplants ~trat, data = exp3)\nsummary(m3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\nlibrary(report)\nreport(m1)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically not significant\nand weak proportion of variance (R2 = 0.07, F(1, 22) = 1.69, p = 0.207, adj. R2\n= 0.03). The model's intercept, corresponding to trat = 0, is at 52.50 (95% CI\n[43.78, 61.22], t(22) = 12.49, p < .001). Within this model:\n\n  - The effect of trat is statistically non-significant and negative (beta =\n-0.24, 95% CI [-0.63, 0.14], t(22) = -1.30, p = 0.207; Std. beta = -0.27, 95%\nCI [-0.69, 0.16])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nreport(m2)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.46, F(1, 22) = 19.05, p < .001, adj.\nR2 = 0.44). The model's intercept, corresponding to trat = 0, is at 60.99 (95%\nCI [53.46, 68.51], t(22) = 16.80, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.70,\n95% CI [-1.03, -0.37], t(22) = -4.37, p < .001; Std. beta = -0.68, 95% CI\n[-1.00, -0.36])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nreport(m3)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.61, F(1, 22) = 34.19, p < .001, adj.\nR2 = 0.59). The model's intercept, corresponding to trat = 0, is at 95.75 (95%\nCI [89.63, 101.87], t(22) = 32.43, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.76,\n95% CI [-1.03, -0.49], t(22) = -5.85, p < .001; Std. beta = -0.78, 95% CI\n[-1.06, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\ng1 <- exp1 |>\n  ggplot(aes(trat, nplants)) +\n  geom_point() +\n  geom_abline(intercept = 52.5, slope = -0.24) +\n  ylim(0, max(estande$nplants)) +\n  geom_smooth(method = \"lm\", se = F) +\ntheme_bw() +\n  annotate(geom = \"text\", x = 24, y = 70, \n           label = \"y = 52.5-0.24x\")\n\n\ng2 <- exp2 |>\n  ggplot(aes(trat, nplants)) +\n  geom_point() +\n  geom_abline(intercept = 52.5, slope = -0.24) +\n  ylim(0, max(estande$nplants)) +\n  geom_smooth(method = \"lm\", se = F) +\ntheme_bw() +\n  annotate(geom = \"text\", x = 24, y = 70, \n           label = \"y = 52.5-0.24x\")\n\n\ng3 <- exp3 |>\n  ggplot(aes(trat, nplants)) +\n  geom_point() +\n  geom_abline(intercept = 52.5, slope = -0.24) +\n  ylim(0, max(estande$nplants)) +\n  geom_smooth(method = \"lm\", se = F) +\ntheme_bw() +\n  annotate(geom = \"text\", x = 24, y = 70, \n           label = \"y = 52.5-0.24x\")\n\n\nlibrary(patchwork)\ng1 + g2\n\n\n\n\n\ng1|g2|g3\n\n\n\n\n\nlibrary(lme4)\nmix <- lmer(nplants ~ trat + (trat|exp), \n            data = estande)\nsummary(mix)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nlibrary(car)\nanova(mix)\n\nAnalysis of Variance Table\n     npar Sum Sq Mean Sq F value\ntrat    1 2012.5  2012.5  11.985\n\n\n\nlm1 <- lm(nplants~trat, data = exp3)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\nglm1 <- glm(nplants~trat, family = \"gaussian\", data = exp3)\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\n\n\nglm2 <- glm(nplants~trat + (1|bloco), family = poisson(link = \"log\"), data = exp3)\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat + (1 | bloco), family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients: (1 not defined because of singularities)\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    4.571590   0.029539 154.762  < 2e-16 ***\ntrat          -0.009965   0.001488  -6.697 2.13e-11 ***\n1 | blocoTRUE        NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAIC(glm1)\n\n[1] 185.0449\n\nAIC(glm2)\n\n[1] 183.9324"
  },
  {
    "objectID": "AULA 14.html",
    "href": "AULA 14.html",
    "title": "AULA 14",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(ggtext)\nlibrary(ggplot2)\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\n\nestande |>\n  ggplot(aes(trat, nplants, group = exp)) +\n  geom_point() +\n  facet_wrap(~exp) +\n  ylim(0, max(estande$nplants))+\n  geom_smooth(se = F)\n\n\n\n\n\nestande2 <- estande |>\n  filter(exp == 2) |>\n  group_by(trat) |>\n  summarise(mean_nplants = mean(nplants))\n\n\nestande2 |>\n  ggplot(aes(trat, mean_nplants)) +\n  geom_point() +\n  geom_line() +\n  geom_smooth(se = F, formula = y ~ poly(x, 1),\n              method = \"lm\", color = \"black\")+\n  theme_minimal()+\n  annotate(geom = \"text\", x = 25, y = 70, \n           label = \"y = 66.3 - 1.777x + 0.0222x2\n           R2 = 0.88\")\n\n\n\n\n\nestande2 <- estande2 |>\n  mutate(trat2 = trat*2)\n  m1 <- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\nhist(m1$residuals)\n\n\n\n\n\nm2 <- lm(mean_nplants ~ trat+trat2, data = estande2)\nsummary(m2)\n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \ntrat2             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\nAIC(m1, m2)\n\n   df    AIC\nm1  3 45.722\nm2  3 45.722\n\n\n\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\nmofo |> \n  ggplot(aes(inc, yld)) +\n  geom_point() + \n  geom_smooth(se = F, method = \"lm\") + \n  facet_wrap(~study)"
  },
  {
    "objectID": "AULA 14.html#two-response-variables",
    "href": "AULA 14.html#two-response-variables",
    "title": "AULA 14",
    "section": "Two response variables",
    "text": "Two response variables\n\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\nmofo |>\n  ggplot(aes(inc, yld))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")+\n  facet_wrap(~study)\n\n\n\n\n\nmofo1 <- mofo |> \n  filter(study ==2)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n\nshapiro.test(mofo$inc) \n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo$inc\nW = 0.94315, p-value = 0.01507\n\nshapiro.test(mofo$yld)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo$yld\nW = 0.95769, p-value = 0.06216\n\n\n\nmofo1 <- mofo |> \n  filter(study ==2)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n\ncor.test(mofo$inc, mofo$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo$inc and mofo$yld\nt = -2.9274, df = 50, p-value = 0.005133\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5934601 -0.1223842\nsample estimates:\n       cor \n-0.3825092 \n\npcor <- cor(mofo1 |> select(3:5), method = \"spearman\")\n\n\nlibrary(corrplot)\ncorrplot(pcor, \n         method = \"number\", \n         type = \"lower\")"
  },
  {
    "objectID": "AULA 15.html",
    "href": "AULA 15.html",
    "title": "AULA 15",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\nsurvey |>\n  count(year)\n\n# A tibble: 3 × 2\n   year     n\n  <dbl> <int>\n1  2009   265\n2  2010   216\n3  2011   185\n\nq <- table(survey$residue, survey$inc_class)\nchisq.test(q)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 2.6165, df = 1, p-value = 0.1058\n\nfisher.test(q)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  q\np-value = 0.09855\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.4492084 1.0721250\nsample estimates:\nodds ratio \n  0.696718 \n\n\n\nlibrary(janitor)\nsurvey |>\n  tabyl(year, species) |>\n  adorn_percentages()\n\n year      Fgra      Fspp\n 2009 0.8490566 0.1509434\n 2010 0.8657407 0.1342593\n 2011 0.7567568 0.2432432\n\n\n\nsurvey |>\n  count(year, species) |>\nggplot(aes(year, n, fill = species))+\n  geom_col()\n\n\n\n\n\nsurvey |>\n  filter(residue != \"NA\") |>\n  count(residue, species) |>\nggplot(aes(residue, n, fill = species))+\n  geom_col()\n\n\n\n\n\nsurvey |>\n  filter(residue != \"NA\") |>\n  count(residue, inc_class) |>\nggplot(aes(residue, n, fill = inc_class))+\n  geom_col()\n\n\n\n\n\ncurve <- read_excel(\"dados-diversos.xlsx\", \"curve\")\ncurve2 <- curve |>\n  group_by(Irrigation, day) |>\n  summarize(mean_severity = mean(severity), \n            sd_severity = sd(severity))\n\ncurve2 |>\n  ggplot(aes(day, mean_severity, color = Irrigation))+\n  geom_point()+\n  geom_errorbar(aes(ymin = mean_severity - sd_severity, \n                    ymax = mean_severity + sd_severity),\n                width = 0.1)+\n  geom_line()\n\n\n\n\n\nlibrary(epifitter)\ncurve3 <- curve |>\n  group_by(Irrigation, rep) |>\n  summarise(audpc = AUDPC(day, severity, y_proportion = F)) |>\npivot_wider(1, names_from = Irrigation, values_from = audpc)\nt.test(curve3$Drip, curve3$Furrow)\n\n\n    Welch Two Sample t-test\n\ndata:  curve3$Drip and curve3$Furrow\nt = -1.3773, df = 3.079, p-value = 0.26\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.3421436  0.5231436\nsample estimates:\nmean of x mean of y \n 13.38983  13.79933 \n\n\n\nlibrary(gsheet)\ntw <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1t5xftb0xSRPNFhM7h_MiPNtwt2UFUcm9/edit#gid=1594889893\")\n\ntw |>\n  group_by(cult, silicio, hai) |>\n  summarise(mean_lesion = mean(lesion_size),\n            sd_lesion = sd(lesion_size)) |>\n  ggplot(aes(hai, mean_lesion, color = silicio))+\n  geom_line()+\n  geom_point()+\n  geom_errorbar(aes(ymin = mean_lesion - sd_lesion,\n                    ymax = mean_lesion + sd_lesion),\n                width = 0.1)+\n  facet_wrap(~cult)+\n  ggthemes::theme_few()+\n  scale_color_grey()\n\n\n\n\n\nlibrary(agricolae)\ntw2 <- tw |>\n  group_by(exp, cult, silicio, rep) |>\n  summarise(audpc = audpc(hai, lesion_size))\n\n\ntw2 |>\n  ggplot(aes(cult, audpc, color = silicio))+\n  geom_boxplot()+\n  facet_wrap(~exp)\n\n\n\n\n\naov1 <- aov(sqrt(audpc) ~ exp*cult*silicio, data = tw2)\nsummary(aov1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nexp               1   32.7    32.7   1.425   0.2406    \ncult              1  290.6   290.6  12.646   0.0011 ** \nsilicio           1 2355.0  2355.0 102.497 6.13e-12 ***\nexp:cult          1   15.5    15.5   0.674   0.4171    \nexp:silicio       1    4.8     4.8   0.208   0.6508    \ncult:silicio      1  517.8   517.8  22.537 3.43e-05 ***\nexp:cult:silicio  1   12.3    12.3   0.535   0.4694    \nResiduals        35  804.2    23.0                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 observation deleted due to missingness\n\nlibrary(performance)\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.229).\n\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.704).\n\nlibrary(emmeans)\nm1 <- emmeans(aov1, ~cult | silicio, type = \"reponse\")\nm1\n\nsilicio = Si-:\n cult      emmean   SE df lower.CL upper.CL\n Horizonte   38.1 1.50 35     35.1     41.2\n Quartzo     38.8 1.50 35     35.7     41.8\n\nsilicio = Si+:\n cult      emmean   SE df lower.CL upper.CL\n Horizonte   29.7 1.50 35     26.6     32.7\n Quartzo     17.0 1.55 35     13.9     20.1\n\nResults are averaged over the levels of: exp \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95"
  },
  {
    "objectID": "AULA 16.html",
    "href": "AULA 16.html",
    "title": "AULA 16",
    "section": "",
    "text": "library(tidyverse)\nlibrary(r4pde)\nlibrary(ggplot2)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(remotes)\nlibrary(ggspatial)\nlibrary(readxl)\n\n\nsbr <- RustSoybean\nBRA <- ne_countries(country = \"Nigeria\",\n                    returnclass = \"sf\")\nggplot(BRA)+geom_sf(fill = \"white\")\n\n\n\n\n\nBRA <- ne_states(country = \"Nigeria\",\n                    returnclass = \"sf\")\nggplot(BRA)+geom_sf(color = \"white\", fill = \"darkgreen\")+\n  theme_void()\n\n\n\n\n\nsbr <- RustSoybean\nsbr2 <- sbr |>\n  separate(planting, into = c(\"year\", \"month\", \"day\"),\n           sep = \"-\", remove = FALSE)\n\nBRA <- ne_states(country = \"brazil\",\n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nggplot(BRA)+\n  geom_sf(fill = \"white\") + \n  #geom_sf(data = MG, color = \"black\", fill = \"blue\")\n\ngeom_point(data = sbr2, \n             aes(longitude, latitude, color = year), \n             alpha = 0.5) + \n  geom_hline(yintercept = -23, \n             linetype = \"dashed\",\n             color = \"gray\") +\n  theme_classic() +\n  annotation_north_arrow(style = north_arrow_nautical()) +\n  annotation_scale(location = \"br\") + theme(legend.position = \"top\")\n\n\n\n\n\nggplot(BRA) + \n  geom_sf(fill = \"white\") + \n  #geom_sf(data = MG, color = \"black\", fill = \"blue\")\n  geom_point(data = sbr2, \n             aes(longitude, latitude, color = year, size = severity), \n             alpha = 0.5) + \n  geom_hline(yintercept = -23, \n             linetype = \"dashed\",\n             color = \"gray\") +\n  theme_classic() +\n  annotation_north_arrow(style = north_arrow_nautical()) +\n  annotation_scale(location = \"br\")"
  },
  {
    "objectID": "AULA 17.html",
    "href": "AULA 17.html",
    "title": "AULA 17",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(gsheet)\ndat <- gsheet2tbl(\"https://docs.google.com/spreadsheets/u/3/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit?usp=drive_web&ouid=112660568480999087067\")\n\n\noptions(scipen=999)\ndat2 <- dat |> \n  select(-Isolate, -Population) |> \n  group_by(Code, Year, Dose) |> \n  summarise(GC_mean = mean(GC))\n\nFGT152 <- dat2 |> \n  filter(Code == \"FGT152\")\n\nFGT152 |> \n  ggplot(aes(factor(Dose), GC_mean)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~Code)\n\n\n\ndat2 |> \n  ggplot(aes(factor(Dose), GC_mean)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~Code)\n\n\n\n\n##EC50 with DRM package\n\nlibrary(drc)\ndrcl <- drm(GC_mean ~ Dose, data = FGT152, fct = LL.3())\nsummary(drcl)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value     p-value    \nb:(Intercept)  0.401905   0.053427  7.5225    0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 0.000005302 ***\ne:(Intercept)  7.220130   2.340119  3.0854    0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n\nplot(drcl)\n\n\n\nED(drcl, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50  7.22013    2.34012  0.72292 13.71734\n\n\n\nlibrary(drc)\ndrc2 <- drm(GC_mean ~ Dose, data = FGT152, fct = W1.3())\nsummary(drc2)\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value    p-value    \nb:(Intercept)  0.28354    0.04760  5.9567   0.003987 ** \nd:(Intercept) 48.38112    2.09996 23.0390 0.00002103 ***\ne:(Intercept) 30.12379   12.58003  2.3946   0.074796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.680509 (4 degrees of freedom)\n\nplot(drc2)\n\n\n\nED(drc2, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error   Lower   Upper\ne:1:50   8.2704     3.6719 -1.9246 18.4653\n\n\n\nAIC(drcl)\n\n[1] 33.60846\n\nAIC(drc2)\n\n[1] 37.75192\n\n\n##Kaique developed a package called ec50estimator\n\nlibrary(ec50estimator)\ndf_ec50 <- estimate_EC50(GC_mean ~Dose,\n                         data = dat2,\n                         isolate_col = \"Code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\ndf_ec50 |> \n  ggplot(aes(Estimate)) +\n  geom_histogram()\n\n\n\n\n\ndf_ec50 |> \n  ggplot(aes(Estimate, reorder(ID, Estimate))) +\n  geom_point() +\n  geom_errorbar(aes(xmin=Lower,\n                    xmax=Upper,\n                    width =0.1)) +\n  xlim(0,30)"
  },
  {
    "objectID": "AULA 18.html",
    "href": "AULA 18.html",
    "title": "AULA 18",
    "section": "",
    "text": "##TRANSFORMATION OF BOX COX\nThe Analysis of Variance model assumes that there is homoscedasticity, that is, that the treatments present the same variability.\nSometimes this assumption may not be met and thus, to correct this problem, there is a way out that is sometimes quite simple, which is data transformation.\nThis technique consists of using a mathematical device to make the ANOVA model valid.\nBOX COX TRANSFORMATION\nStatisticians George Box and David Cox developed a procedure for identifying an appropriate exponent (Lambda = 1) to use to transform data into “normal form”. When the Lambda value is 1, no transformation is needed, it produces results identical to the originals. The Lambda value indicates the power to which all data should be raised. For this, the Box-Cox power transformation searches from Lambda = -5 to Lamba = +5 until it finds the best value. The table below shows some common Box-Cox transformations, where Y’ is the transformation of the original Y data. Note that for Lambda = 0, the transformation is NOT Y 0 (because it would be 1 for every value), but the logarithm of Y .\n\n\n\n1\nY'\n\n\n-2\nY-2 = 1/Y2\n\n\n-1\nY-1 = 1/Y1\n\n\n-0.5\nY-0.5 = 1/(Sqrt(Y))\n\n\n0\nlog(Y)\n\n\n0.5\nY0.5 = Sqrt(Y)\n\n\n1\nY1 = Y\n\n\n2\nY2\n\n\n\nThe BOXCOX function was implemented in the MASS package. the lamba (λ) is used to transform the response variable by the formula “responsevariable ^ lambda - 1.”\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\nmicelial <- micelial |> \n  mutate(inc = inf_seeds/n_seeds*100,\n         rank_inc = rank(inc))\n\n# rank transforms data when you have two factors. rank transforms the response variable to two factors\n\nrank_anova <- aov(rank_inc ~ treat*dose, data = micelial)\nsummary(rank_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 220.00  220.00  14.204 0.00168 **\ndose         1 105.34  105.34   6.801 0.01904 * \ntreat:dose   1  80.34   80.34   5.187 0.03684 * \nResiduals   16 247.82   15.49                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(emmeans)\nmeans_rank <- emmeans(rank_anova, ~ treat | dose)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_rank)\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.90 1.76 16     3.17     10.6  1    \n Ionic liquid  18.00 1.76 16    14.27     21.7   2   \n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.75 1.97 16     2.58     10.9  1    \n Ionic liquid   9.75 1.61 16     6.34     13.2  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n# use boxcox\n\nlibrary(MASS)\n\n# creating the insect object\n\ninsects <- tibble::as_tibble(InsectSprays)|> \n  dplyr::select(spray, count)\ninsects\n\n# A tibble: 72 × 2\n   spray count\n   <fct> <dbl>\n 1 A        10\n 2 A         7\n 3 A        20\n 4 A        14\n 5 A        14\n 6 A        12\n 7 A        10\n 8 A        23\n 9 A        17\n10 A        20\n# ℹ 62 more rows\n\n\n\nb <- boxcox(lm(insects$count+0.1 ~ 1)) \n\n\n\n# the value 0.1 is because there was zero in the data; insects$count is the response variable\n\n\n# Find the lambda\n\nlambda <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\n\n# After finding the lambda, the response variable is transformed with the formula below\n# insects$count2 creates count2 automatically, the transformed lambda\n\ninsects$count2 <- (insects$count ^ lambda - 1) / lambda \ninsects$count2 \n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n# response transformed variable\n\n\n## very asymmetrical\n\nhist(insects$count)\n\n\n\n\n\n# more symmetrical\n\nhist(insects$count2)\n\n\n\n\n\ninsects$count2\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n##The transformed lambda is used in the ANOVA"
  },
  {
    "objectID": "AULA 2.html",
    "href": "AULA 2.html",
    "title": "AULA 2",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metafor)\nlibrary(gsheet)\nlibrary(r4pde)\n\n##Another Package\n\nlibrary(dplyr)\narrange(mtcars, cyl, disp)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n\narrange(mtcars, mpg)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n\nOrange\n\nGrouped Data: circumference ~ age | Tree\n   Tree  age circumference\n1     1  118            30\n2     1  484            58\n3     1  664            87\n4     1 1004           115\n5     1 1231           120\n6     1 1372           142\n7     1 1582           145\n8     2  118            33\n9     2  484            69\n10    2  664           111\n11    2 1004           156\n12    2 1231           172\n13    2 1372           203\n14    2 1582           203\n15    3  118            30\n16    3  484            51\n17    3  664            75\n18    3 1004           108\n19    3 1231           115\n20    3 1372           139\n21    3 1582           140\n22    4  118            32\n23    4  484            62\n24    4  664           112\n25    4 1004           167\n26    4 1231           179\n27    4 1372           209\n28    4 1582           214\n29    5  118            30\n30    5  484            49\n31    5  664            81\n32    5 1004           125\n33    5 1231           142\n34    5 1372           174\n35    5 1582           177\n\nurl <- 'docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo'\nmtcars <- gsheet2tbl(url)\n\nd <- gsheet2tbl('docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo')\n\n\nb <- mtcars\nc = b\nc <- b\nlibrary(remotes)\n#install_github(\"emdelponte/r4pde\")\n\nlibrary(r4pde)\nhead(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\n\ntail(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  26       4 120.     91  4.43  2.14  16.7     0     1     5     2\n2  30.4     4  95.1   113  3.77  1.51  16.9     1     1     5     2\n3  15.8     8 351     264  4.22  3.17  14.5     0     1     5     4\n4  19.7     6 145     175  3.62  2.77  15.5     0     1     5     6\n5  15       8 301     335  3.54  3.57  14.6     0     1     5     8\n6  21.4     4 121     109  4.11  2.78  18.6     1     1     4     2\n\n\n##USage: arugment expected between relatives\n\nunit <- c(1:12)\nclass <- c(2,3,1,1,3,4,5,0,2,5,2,1)\nratings <- data.frame(unit, class)\nDSI(unit = ratings$unit, class = ratings$class, max = 6)\n\n[1] 40.27778\n\nDSI(unit = ratings$unit, \n    class = ratings$class, \n    6)\n\n[1] 40.27778\n\nratings$class\n\n [1] 2 3 1 1 3 4 5 0 2 5 2 1\n\nmean(ratings$class)\n\n[1] 2.416667\n\nsd(ratings$class)\n\n[1] 1.621354\n\nsummary(ratings)\n\n      unit           class      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.: 3.75   1st Qu.:1.000  \n Median : 6.50   Median :2.000  \n Mean   : 6.50   Mean   :2.417  \n 3rd Qu.: 9.25   3rd Qu.:3.250  \n Max.   :12.00   Max.   :5.000  \n\nsummary(ratings$class)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   2.000   2.417   3.250   5.000 \n\nsummary(class)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   2.000   2.417   3.250   5.000"
  },
  {
    "objectID": "AULA 3.html",
    "href": "AULA 3.html",
    "title": "AULA 3",
    "section": "",
    "text": "cars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ncars2 <- cars\nspeed <- cars2$speed\nspeed\n\n [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25"
  },
  {
    "objectID": "AULA 3.html#load-dataset-of-excel",
    "href": "AULA 3.html#load-dataset-of-excel",
    "title": "AULA 3",
    "section": "Load Dataset of Excel",
    "text": "Load Dataset of Excel\n\nlibrary(tidyverse)\nlibrary(readxl)\ndf <- read_excel(\"dados-diversos.xlsx\")\nescala1 <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nescala2 <- read_excel(\"dados-diversos.xlsx\", 2)"
  },
  {
    "objectID": "AULA 3.html#loading-csv",
    "href": "AULA 3.html#loading-csv",
    "title": "AULA 3",
    "section": "Loading CSV",
    "text": "Loading CSV\n\nlibrary(tidyverse)\nlibrary(gsheet)\n\nmagnesio2 <- read_csv(\"dados-diversos2.csv\")\nmagnesio3 <- read_csv(\"dados-diversos2.csv\")\nmagnesio3\n\n# A tibble: 60 × 4\n   Irrigation   rep   day severity\n   <chr>      <dbl> <dbl>    <dbl>\n 1 Furrow         1     0     0.01\n 2 Furrow         2     0     0.01\n 3 Furrow         3     0     0.01\n 4 Furrow         1     7     0.04\n 5 Furrow         2     7     0.04\n 6 Furrow         3     7     0.04\n 7 Furrow         1    14     0.1 \n 8 Furrow         2    14     0.1 \n 9 Furrow         3    14     0.11\n10 Furrow         1    21     0.11\n# ℹ 50 more rows\n\n\n\nsheet <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\n\nsheet2 <- gsheet2tbl (\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=366054269\")\n\nsheetcsv <- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/fusarium_banana.csv\")\n\nlibrary(googlesheets4)"
  },
  {
    "objectID": "AULA 4.html",
    "href": "AULA 4.html",
    "title": "AULA 4",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(readxl)\n\nlibrary(csvread)\nmg <- read_csv(\"dados-diversos2.csv\")\n\nmg |> \n  ggplot(aes(Irrigation, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)\n\n\n\nmg |> \n  #filter(rep ==1) |> \nggplot(aes(day, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\ngeom_line()+\nfacet_wrap(~rep)\n\n\n\n\n\nmg |> \n  filter(rep == 2) |> \nggplot(aes(day, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\ngeom_line()\n\n\n\n\n\nmg |> \nggplot(aes(Irrigation, severity, shape = Irrigation))+\n  geom_boxplot()+\ngeom_point(alpha = 0.5)\n\n\n\n\n\nmg |> \n  select(day, rep, severity) |> \n  group_by(day) |> \n  summarize(sev = mean(severity)) |> \nggplot(aes(day, sev))+\n  geom_point()\n\n\n\n\n\nmg2 <- mg |> \n  select(day, rep, severity) |> \n  group_by(day) |> \n  summarize(sev = mean(severity))  \n  \n mg2 |>  \nggplot(aes(day, sev*100))+\n  geom_point(size = 3, color = \"darkorange\")+\n   geom_line(color = \"darkorange\")+\n   ylim(0,100)+\n   scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42, 49, 56, 63))+\n   scale_y_continuous(n.breaks = 10, limits = c(0,100))+\n   labs(x = \"Time (days)\", y = \"severity (%)\", title = \"my first ggplot\", subtitle = \"it is beautiful\", caption = \"Source: FIP 606\")+\n theme_classic()+\n   theme(plot.title = element_text(hjust = 0.5))\n\n\n\n ggsave(\"myfirstggplot.png\", bg = \"white\", width = 4, height = 3)"
  },
  {
    "objectID": "AULA 5.html",
    "href": "AULA 5.html",
    "title": "AULA 5",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\nmg <- read_excel(\"dados-diversos.xlsx\")\n\n\nmg |> \nggplot(aes(trat,comp))+\n  geom_boxplot(color = \"red\", fill = \"blue\", outlier.color = NA, width = 0.2)+\n  geom_jitter(width = 0.1, height = 0, size = 2, color = \"steelblue\")+\n  scale_y_continuous(limits = c(5, 20), n.breaks = 10)+\n  labs(y = \"lesion size (mm)\",\n       x = \"\")+\n  theme_bw()\n\n\n\nggsave(\"second_graph.png\", bg = \"white\")\n\n\np_box <- mg |> \n  group_by(trat) |> \n  summarise(comp_mean = mean(comp),\n            comp_sd = sd(comp)) |> \n            ggplot(aes(trat, comp_mean))+\n            geom_col(color = \"orange\", fill = \"orange\", width = 0.5)+\n          scale_y_continuous(limits = c(0, 20), n.breaks = 6)+\ngeom_errorbar(aes(ymin = comp_mean - comp_sd, \n                  ymax = comp_mean + comp_sd, \n                  width = 0.05))\n\n\nlibrary(ggthemes)\np_means <- mg |> \n  group_by(trat) |> \n  summarise(comp_mean = mean(comp),\n            comp_sd = sd(comp)) |> \n            ggplot(aes(trat, comp_mean))+\n            geom_col(color = \"orange\", fill = \"orange\", width = 0.5)+\n  geom_point()+\n          scale_y_continuous(limits = c(6, 20), n.breaks = 6)+\ngeom_errorbar(aes(ymin = comp_mean - comp_sd, \n                  ymax = comp_mean + comp_sd, \n                  width = 0.1))+\n  theme_classic()\n\n\nggsave(\"third_graph.png\", bg = \"white\",\n       width = 4, \n      height = 4)\n\n\nlibrary(patchwork)\n(p_box | p_means)+\nplot_annotation(tag_levels = \"A\",\n                title = \"Impression graph\")\n\n\n\nggsave(\"Fourth_graph.png\")\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", \n                     sheet = \"survey\")\n\nsurvey |> \nfilter(state ==\"RS\") |> \ncount(species, residue) |> \n  ggplot(aes(species, n))+\n  geom_col(width = 0.4, \n           fill = \"steelblue\")+\ncoord_flip()+\n  facet_wrap(~residue, ncol = 1)+\n  labs(x = \"\", y = \"Number of isolates\",\n       title = \"Horizontal bar plot\",\n       subtitle = \"using ggplot\")+\ntheme_bw()\n\n\n\nggsave(\"fifth_graph.png\")"
  },
  {
    "objectID": "AULA 6.html",
    "href": "AULA 6.html",
    "title": "AULA 6",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nfungicida <- read_excel(\"dados-diversos.xlsx\", \"fungicida_campo\")\n\n\nfungicida |> \n  ggplot(aes(trat, sev))+\n  geom_jitter(width = 0.1,\n              color = \"gray60\")+\n  stat_sum(fun = mean,\n           color = \"red\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(trat, sev))+\n  geom_jitter(width = 0.1,\n              color = \"gray60\")+\n  stat_summary(fun.data = mean_se,\n           color = \"red\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(sev, yld, \n             color = trat,\n             size = yld))+\n  geom_jitter(width = 0.1)+\n  geom_point()+\n  scale_color_brewer()\n\n\n\n\n\nlibrary(ggthemes)\nfungicida |> \n  ggplot(aes(sev, yld, \n             color = trat))+\n  geom_jitter(width = 0.1)+\n  geom_point()+\n  scale_color_colorblind()\n\n\n\n\n\nlibrary(ggthemes)\nfungicida |> \n  ggplot(aes(sev, yld, \n             color = trat))+\n  geom_jitter(width = 0.1)+\n  geom_point(width = 0.5)+\n  scale_color_colorblind()\n\n\n\n\n\nlibrary(ggthemes)\nfungicida |> \n  ggplot(aes(sev, yld))+\n  geom_jitter(width = 0.1)+\n  geom_point(size = 3,\n             color = \"gray50\")+\n  scale_color_colorblind()+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"black\",\n              linetype = \"dashed\")\n\n\n\n\n##Factorial Experiment\n\nmilho <-read_excel(\"dados-diversos.xlsx\", \"milho\")\n\n\nmilho |> \nggplot(aes(hybrid, yield))+\ngeom_point(color = \"red\",\n           size = 0.9)\n\n\n\n\n\nmilho |> \nggplot(aes(method, index,\n           colour = method))+\n  geom_jitter(width = 0.1)+\nfacet_wrap(~hybrid)\n\n\n\n\n##HIstogram\n\nmilho |> \n  ggplot(aes(x = yield))+\n  geom_histogram()+\ngeom_histogram(bins = 10,\n               color = \"black\", fill = \"steelblue\")\n\n\n\n\n\nlibrary(patchwork)\ni <- milho |> \n  ggplot(aes(x = index))+\n  geom_histogram()+\ngeom_histogram(bins = 10,\n               color = \"black\", fill = \"steelblue\")\ni\n\n\n\n\n\ny <- milho |> \n  ggplot(aes(x = yield))+\n  geom_histogram()+\ngeom_histogram(bins = 10,\n               color = \"black\", fill = \"steelblue\")\ny\n\n\n\ny+i\n\n\n\n\n\nlibrary(patchwork)\n\n(y+i)+\n  plot_annotation(tag_levels = \"A\",\n                  title = \"Graph Histo\")\n\n\n\nggsave(\"sixth_graph.png\", bg = \"white\")\n\n\ninsect <- read_excel(\"dados-diversos.xlsx\", \"mortalidade\")\n\ninsect |> \n pivot_longer(2:3,\n              names_to = \"status\",\n              values_to = \"value\") |> \n ggplot(aes(inseticida, value, fill = status))+\n geom_col()"
  },
  {
    "objectID": "AULA 7.html",
    "href": "AULA 7.html",
    "title": "AULA 7",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\nmofo |> \n  ggplot(aes(treat, yld)) +\n  geom_col() +\n  geom_point(color = \"red\") +\n  facet_wrap(~study)\n\n\n\n\n###Histogram\n\nh <- mofo |> \n  ggplot(aes(scl)) +\n  geom_histogram(bins = 10)\n\nb <- mofo |> \n  ggplot(aes(scl)) +\n  geom_boxplot()\n\nlibrary(patchwork)\n\nh / b\n\n\n\n\n##How to calculate fast average of the Scl variable within the mofo set\n\nmean(mofo$scl)\n\n[1] 1639.096\n\n\n##Another method\n\nsummary(mofo)\n\n     study          treat         inc             scl            yld      \n Min.   :1.00   Min.   : 1   Min.   : 7.00   Min.   : 119   Min.   :1893  \n 1st Qu.:1.75   1st Qu.: 4   1st Qu.:26.00   1st Qu.: 588   1st Qu.:2438  \n Median :2.50   Median : 7   Median :34.00   Median :1337   Median :2678  \n Mean   :2.50   Mean   : 7   Mean   :35.10   Mean   :1639   Mean   :2780  \n 3rd Qu.:3.25   3rd Qu.:10   3rd Qu.:41.25   3rd Qu.:2382   3rd Qu.:3055  \n Max.   :4.00   Max.   :13   Max.   :76.00   Max.   :6216   Max.   :3702  \n\n\n##For transformation, you can use log or sqrt to create a new variable within dataset showing the transformation values of a given variable\n\nmofo2 <- mofo |> \n  mutate(scl2 = sqrt(scl))\n\nhl <- mofo2 |> \n  ggplot(aes(scl2)) +\n  geom_histogram(bins = 10)\n\nh / hl \n\n\n\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\n\nsurvey |> \n  filter(state == \"RS\") |> \n  count(species, residue) |> \n  arrange (species) |> \n  rename(res = residue) |> \n  mutate(n_class = case_when(\n    n <30 ~ \"baixa\",\n    TRUE ~ \"Alta\"))\n\n# A tibble: 4 × 4\n  species res         n n_class\n  <chr>   <chr>   <int> <chr>  \n1 Fgra    corn      147 Alta   \n2 Fgra    soybean   255 Alta   \n3 Fspp    corn       22 baixa  \n4 Fspp    soybean    26 baixa"
  },
  {
    "objectID": "AULA 8.html",
    "href": "AULA 8.html",
    "title": "AULA 8",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nmicelial <- read_excel(\"dados-diversos.xlsx\",\"micelial\")\nhead(micelial)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.24\n6 Fasi        6  1.29\n\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_boxplot()\n\n\n\n\n\naov1 <- aov(tcm ~  especie, \n            data = micelial)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915               \n\n\n\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov1))\n\n\n\nhist(aov1$residuals)\n\n\n\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n\n\n\n\n\nlibrary(tidyverse)\ninsects <- tbl_df(InsectSprays) |> \n  select(spray, count)\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhead(insects)\n\n# A tibble: 6 × 2\n  spray count\n  <fct> <dbl>\n1 A        10\n2 A         7\n3 A        20\n4 A        14\n5 A        14\n6 A        12\n\ninsects |> \n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\n\nlibrary(performance)\ncheck_heteroscedasticity(aov2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\ncheck_normality(aov2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\n\n\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)"
  },
  {
    "objectID": "AULA 9.html",
    "href": "AULA 9.html",
    "title": "AULA 9",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\ndata_mg <- read_excel(\"dados-diversos.xlsx\")\n\ndat2 <- data_mg |> \n  group_by(trat) |> \n  summarise (mean_comp = mean(comp),\n             sd_comp = sd(comp),\n             var_comp = var(comp),\n             n = n(),\n             se_comp = sd_comp / sqrt(n-1),\n             ci = se_comp * qt(0.025, df = 9))\ndat2\n\n# A tibble: 2 × 7\n  trat    mean_comp sd_comp var_comp     n se_comp     ci\n  <chr>       <dbl>   <dbl>    <dbl> <int>   <dbl>  <dbl>\n1 Mg2          10.5    1.54     2.39    10   0.515 -1.16 \n2 control      15.7    1.27     1.61    10   0.424 -0.958\n\n\n\ndat2 |> \n  ggplot(aes(trat, mean_comp)) +\n  geom_col(color = \"orange\", fill = \"orange\", width = 0.5) +\n  geom_errorbar(aes(\n    ymin = mean_comp - se_comp,\n    ymax = mean_comp + se_comp), \n    width = 0.1) +\nylim(0, 20)\n\n\n\n\n\ndat2 |> \n  ggplot(aes(trat, mean_comp)) +\n  geom_col(color = \"orange\", fill = \"orange\", width = 0.5) +\n  geom_errorbar(aes(\n    ymin = mean_comp - ci,\n    ymax = mean_comp + ci), \n    width = 0.1) +\nylim(0, 20) +\n  labs(x = \"\", y = \"Mean size (mm)\")\n\n\n\n\n\ndata_mg2 <- data_mg |> \n  pivot_wider(1, \n              names_from = trat, \n              values_from = comp)\ndata_mg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   <dbl> <dbl>   <dbl>\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\n\n\nt.test(data_mg2$Mg2, data_mg2$control, paired = F)\n\n\n    Welch Two Sample t-test\n\ndata:  data_mg2$Mg2 and data_mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\n\ndata_mg |> \n  ggplot(aes(trat, comp)) +\ngeom_jitter(width = 0.5, shape = 2)\n\n\n\n\n##homocedasticidade\n\nattach(data_mg2)\nvar.test(Mg2, control)\n\n\n    F test to compare two variances\n\ndata:  Mg2 and control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\nMg2\n\n [1]  9.0 12.5 10.0  8.0 13.2 11.0 10.8  9.5 10.8 10.4\n\ncontrol\n\n [1] 13.72 15.91 15.70 14.20 15.90 16.54 18.00 14.40 16.41 16.00\n\n\n##Normalidade\n\nshapiro.test(Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\nshapiro.test(control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n\n\n##Analyze visual normalidade\n\nqqnorm(Mg2)\nqqline(Mg2)\n\n\n\nqqnorm(control)\nqqline(control)\n\n\n\n\n##Preanalysis preparation\n\nlibrary(readxl)\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\nescala2 <- escala |>\n  select(assessment, rater, acuracia) |> \n  pivot_wider(1, \n              names_from = assessment,\n              values_from = acuracia)\nescala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   <chr>   <dbl>  <dbl>\n 1 A       0.809  0.907\n 2 B       0.722  0.913\n 3 C       0.560  0.915\n 4 D       0.818  0.960\n 5 E       0.748  0.959\n 6 F       0.695  0.903\n 7 G       0.807  0.851\n 8 H       0.781  0.880\n 9 I       0.776  0.950\n10 J       0.618  0.944\n\n\n\nattach(escala2)\nt.test(Aided1, Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  Aided1 and Unaided\nt = 5.9364, df = 9, p-value = 0.000219\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1144707 0.2554241\nsample estimates:\nmean difference \n      0.1849474 \n\nvar.test(Aided1, Unaided)\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\nshapiro.test(Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Aided1\nW = 0.92775, p-value = 0.4261\n\n\n\nattach(escala2)\nt_escala <- t.test(Aided1, Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\nvar.test(Aided1, Unaided)\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\nshapiro.test(Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Unaided\nW = 0.87462, p-value = 0.1131\n\nlibrary(report)\nreport(t_escala)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between Aided1 and Unaided (mean\ndifference = 0.18) suggests that the effect is positive, statistically\nsignificant, and large (difference = 0.18, 95% CI [0.11, 0.26], t(9) = 5.94, p\n< .001; Cohen's d = 1.88, 95% CI [0.81, 2.91])\n\nwilcox.test(Aided1, Unaided)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  Aided1 and Unaided\nW = 100, p-value = 1.083e-05\nalternative hypothesis: true location shift is not equal to 0\n\nlibrary(rstatix)\n\n\nescala |> \n ggplot(aes(assessment, acuracia)) +\n  geom_boxplot()\n\n\n\n\n\nescala |> \n ggplot(aes(assessment, precisao)) +\n  geom_boxplot()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HELLO",
    "section": "",
    "text": "About me: My name is Gbindinnuola, a Ph.D. student of Plant Pathology at Universidade Federal de Vicosa, Vicosa, Minas Gerais, Brazil.\nI love good music, adventure and movie. Likewise, I actively engage in community service because service to humanity is of great importance.\nUtmost, I love God and one of my favourite Bible passages is Isaiah 40."
  }
]